{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "import hashlib"
      ],
      "metadata": {
        "id": "xlvO7cp9lj5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_TOKEN = \"####\"\n",
        "\n",
        "MAX_SAMPLES = 100\n",
        "LANGUAGES = [\"python\", \"java\"]\n",
        "\n",
        "VALID_LICENSES = [\"mit\", \"apache-2.0\", \"bsd-3-clause\", \"bsd-2-clause\"]\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github.v3+json\"\n",
        "}\n",
        "\n",
        "dataset = []\n",
        "seen_hashes = set()"
      ],
      "metadata": {
        "id": "zzEpziWWlqo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hashing to avoid duplicates\n",
        "def hash_text(text):\n",
        "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n"
      ],
      "metadata": {
        "id": "ChQRDjN7lv2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GitHub search\n",
        "\n",
        "def search_github_files(language, page=1):\n",
        "    query = f\"language:{language} def in:file\" if language == \"python\" else f\"language:{language} in:file\"\n",
        "    url = f\"https://api.github.com/search/code?q={query}&page={page}&per_page=50\"\n",
        "    return requests.get(url, headers=headers).json()\n",
        "\n"
      ],
      "metadata": {
        "id": "QwnCDv4Gl3-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch repo license\n",
        "\n",
        "def get_repo_license(repo_full_name):\n",
        "    url = f\"https://api.github.com/repos/{repo_full_name}/license\"\n",
        "    res = requests.get(url, headers=headers).json()\n",
        "    if \"license\" in res and res[\"license\"]:\n",
        "        return res[\"license\"][\"spdx_id\"].lower()\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "pEuLG29hl7I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download raw code\n",
        "\n",
        "def download_raw_file(item):\n",
        "    url = item[\"html_url\"].replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\")\n",
        "    res = requests.get(url, headers=headers)\n",
        "    return res.text if res.status_code == 200 else None\n",
        "\n"
      ],
      "metadata": {
        "id": "5R6_1QsXl-P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering rules to avoid getting ai generated comments\n",
        "\n",
        "BANNERS = [\"====\", \"----\", \"****\", \"#####\", \"{{{\", \"}}}\", \"========\"]\n",
        "VERB_KEYWORDS = [\n",
        "    \"return\", \"compute\", \"calculate\", \"parse\", \"load\", \"read\", \"build\",\n",
        "    \"convert\", \"check\", \"verify\", \"open\", \"write\", \"download\",\n",
        "    \"initialize\", \"process\", \"retrieve\", \"extract\"\n",
        "]\n",
        "\n",
        "\n",
        "def is_valid_comment(comment):\n",
        "    if len(comment.strip()) == 0:\n",
        "        return False\n",
        "\n",
        "    if any(b in comment for b in BANNERS):\n",
        "        return False\n",
        "\n",
        "    if len(comment.split(\"\\n\")) > 10:\n",
        "        return False  # too big = probably file header\n",
        "\n",
        "    # Require at least one meaningful verb\n",
        "    if not any(v in comment.lower() for v in VERB_KEYWORDS):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n"
      ],
      "metadata": {
        "id": "E6b-o9VzmFMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Python docstrings + function signature\n",
        "\n",
        "def extract_python(code):\n",
        "    samples = []\n",
        "\n",
        "    # Regex for Python docstring + function\n",
        "    pattern = r'def\\s+(\\w+)\\s*\\([^)]*\\)\\s*:[\\s\\n]*(\"\"\"([\\s\\S]*?)\"\"\"|\\'\\'\\'([\\s\\S]*?)\\'\\'\\')'\n",
        "    matches = re.finditer(pattern, code)\n",
        "\n",
        "    for m in matches:\n",
        "        func_name = m.group(1)\n",
        "        raw_comment = m.group(3) or m.group(4)\n",
        "        full_match = m.group(0)\n",
        "\n",
        "        if not is_valid_comment(raw_comment):\n",
        "            continue\n",
        "\n",
        "        # function size filter\n",
        "        lines = full_match.strip().split(\"\\n\")\n",
        "        if len(lines) < 3 or len(lines) > 80:\n",
        "            continue\n",
        "\n",
        "        samples.append({\n",
        "            \"language\": \"python\",\n",
        "            \"human_comment\": raw_comment.strip(),\n",
        "            \"code\": full_match.strip()\n",
        "        })\n",
        "\n",
        "    return samples\n",
        "\n"
      ],
      "metadata": {
        "id": "0m8wM0aGmI1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Java Javadoc + method signature\n",
        "\n",
        "def extract_java(code):\n",
        "    samples = []\n",
        "\n",
        "    pattern = r'(/\\*\\*[\\s\\S]*?\\*/)\\s*(public|private|protected)?\\s+\\w[\\w<>]*\\s+\\w+\\([^)]*\\)\\s*\\{'\n",
        "    matches = re.finditer(pattern, code)\n",
        "\n",
        "    for m in matches:\n",
        "        comment = m.group(1)\n",
        "        code_snippet = m.group(0)\n",
        "\n",
        "        if not is_valid_comment(comment):\n",
        "            continue\n",
        "\n",
        "        # function size filter\n",
        "        lines = code_snippet.strip().split(\"\\n\")\n",
        "        if len(lines) < 3 or len(lines) > 80:\n",
        "            continue\n",
        "\n",
        "        samples.append({\n",
        "            \"language\": \"java\",\n",
        "            \"human_comment\": comment.strip(),\n",
        "            \"code\": code_snippet.strip()\n",
        "        })\n",
        "\n",
        "    return samples\n",
        "\n"
      ],
      "metadata": {
        "id": "6bX_IEdgmMRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpnO98NvU-8D",
        "outputId": "24f0aac1-5de3-432a-a237-490fa16531f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Searching python repositories...\n",
            "âœ” Sample 1 added\n",
            "âœ” Sample 2 added\n",
            "âœ” Sample 3 added\n",
            "âœ” Sample 4 added\n",
            "âœ” Sample 5 added\n",
            "âœ” Sample 6 added\n",
            "âœ” Sample 7 added\n",
            "âœ” Sample 8 added\n",
            "âœ” Sample 9 added\n",
            "âœ” Sample 10 added\n",
            "âœ” Sample 11 added\n",
            "âœ” Sample 12 added\n",
            "âœ” Sample 13 added\n",
            "âœ” Sample 14 added\n",
            "âœ” Sample 15 added\n",
            "âœ” Sample 16 added\n",
            "âœ” Sample 17 added\n",
            "âœ” Sample 18 added\n",
            "âœ” Sample 19 added\n",
            "âœ” Sample 20 added\n",
            "âœ” Sample 21 added\n",
            "âœ” Sample 22 added\n",
            "âœ” Sample 23 added\n",
            "âœ” Sample 24 added\n",
            "âœ” Sample 25 added\n",
            "âœ” Sample 26 added\n",
            "âœ” Sample 27 added\n",
            "âœ” Sample 28 added\n",
            "âœ” Sample 29 added\n",
            "âœ” Sample 30 added\n",
            "âœ” Sample 31 added\n",
            "âœ” Sample 32 added\n",
            "âœ” Sample 33 added\n",
            "âœ” Sample 34 added\n",
            "âœ” Sample 35 added\n",
            "âœ” Sample 36 added\n",
            "âœ” Sample 37 added\n",
            "âœ” Sample 38 added\n",
            "âœ” Sample 39 added\n",
            "âœ” Sample 40 added\n",
            "âœ” Sample 41 added\n",
            "âœ” Sample 42 added\n",
            "âœ” Sample 43 added\n",
            "âœ” Sample 44 added\n",
            "âœ” Sample 45 added\n",
            "âœ” Sample 46 added\n",
            "âœ” Sample 47 added\n",
            "âœ” Sample 48 added\n",
            "âœ” Sample 49 added\n",
            "âœ” Sample 50 added\n",
            "âœ” Sample 51 added\n",
            "âœ” Sample 52 added\n",
            "âœ” Sample 53 added\n",
            "âœ” Sample 54 added\n",
            "âœ” Sample 55 added\n",
            "âœ” Sample 56 added\n",
            "âœ” Sample 57 added\n",
            "âœ” Sample 58 added\n",
            "âœ” Sample 59 added\n",
            "âœ” Sample 60 added\n",
            "âœ” Sample 61 added\n",
            "âœ” Sample 62 added\n",
            "âœ” Sample 63 added\n",
            "âœ” Sample 64 added\n",
            "âœ” Sample 65 added\n",
            "âœ” Sample 66 added\n",
            "âœ” Sample 67 added\n",
            "âœ” Sample 68 added\n",
            "âœ” Sample 69 added\n",
            "âœ” Sample 70 added\n",
            "âœ” Sample 71 added\n",
            "âœ” Sample 72 added\n",
            "âœ” Sample 73 added\n",
            "âœ” Sample 74 added\n",
            "âœ” Sample 75 added\n",
            "âœ” Sample 76 added\n",
            "âœ” Sample 77 added\n",
            "âœ” Sample 78 added\n",
            "âœ” Sample 79 added\n",
            "âœ” Sample 80 added\n",
            "âœ” Sample 81 added\n",
            "âœ” Sample 82 added\n",
            "âœ” Sample 83 added\n",
            "âœ” Sample 84 added\n",
            "âœ” Sample 85 added\n",
            "âœ” Sample 86 added\n",
            "âœ” Sample 87 added\n",
            "âœ” Sample 88 added\n",
            "âœ” Sample 89 added\n",
            "âœ” Sample 90 added\n",
            "âœ” Sample 91 added\n",
            "âœ” Sample 92 added\n",
            "âœ” Sample 93 added\n",
            "âœ” Sample 94 added\n",
            "âœ” Sample 95 added\n",
            "âœ” Sample 96 added\n",
            "âœ” Sample 97 added\n",
            "âœ” Sample 98 added\n",
            "âœ” Sample 99 added\n",
            "âœ” Sample 100 added\n",
            "\n",
            "ğŸ‰ DONE!\n",
            "Collected 100 clean, meaningful samples â†’ clean_dataset.json\n"
          ]
        }
      ],
      "source": [
        "# main data collection loop\n",
        "\n",
        "def collect():\n",
        "    global dataset\n",
        "\n",
        "    for lang in LANGUAGES:\n",
        "        print(f\"\\nğŸ” Searching {lang} repositories...\")\n",
        "\n",
        "        page = 1\n",
        "        while len(dataset) < MAX_SAMPLES:\n",
        "            results = search_github_files(lang, page)\n",
        "\n",
        "            if \"items\" not in results:\n",
        "                print(\" ! API rate limit or no more results.\")\n",
        "                return\n",
        "\n",
        "            for item in results[\"items\"]:\n",
        "                repo_name = item[\"repository\"][\"full_name\"]\n",
        "\n",
        "                # Check repo license\n",
        "                license_key = get_repo_license(repo_name)\n",
        "                if license_key not in VALID_LICENSES:\n",
        "                    continue\n",
        "\n",
        "                # Download file raw content\n",
        "                code = download_raw_file(item)\n",
        "                if not code:\n",
        "                    continue\n",
        "\n",
        "                # Extract relevant code-comment pairs\n",
        "                if lang == \"python\":\n",
        "                    extracted = extract_python(code)\n",
        "                else:\n",
        "                    extracted = extract_java(code)\n",
        "\n",
        "                for s in extracted:\n",
        "                    # Deduplication\n",
        "                    h = hash_text(s[\"code\"] + s[\"human_comment\"])\n",
        "                    if h in seen_hashes:\n",
        "                        continue\n",
        "                    seen_hashes.add(h)\n",
        "\n",
        "                    # Add metadata\n",
        "                    s[\"license\"] = license_key\n",
        "                    s[\"source_repo\"] = f\"https://github.com/{repo_name}\"\n",
        "                    dataset.append(s)\n",
        "\n",
        "                    print(f\"âœ” Sample {len(dataset)} added\")\n",
        "\n",
        "                    if len(dataset) >= MAX_SAMPLES:\n",
        "                        return\n",
        "\n",
        "            page += 1\n",
        "\n",
        "\n",
        "# RUN SCRIPT\n",
        "\n",
        "collect()\n",
        "\n",
        "with open(\"clean_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dataset, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n DONE ! \")\n",
        "print(f\"Collected {len(dataset)} clean, meaningful samples â†’ clean_dataset.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write dataset_description.md\n",
        "\n",
        "description = f\"\"\"\n",
        "# Dataset Description\n",
        "\n",
        "This dataset contains {len(dataset)} highâ€“quality codeâ€“comment pairs\n",
        "automatically extracted from openâ€“source GitHub repositories.\n",
        "\n",
        "## Key Features\n",
        "- Languages: Python and Java\n",
        "- Only human-written function-level comments (docstrings / Javadoc)\n",
        "- Functions filtered for clarity and meaningful documentation\n",
        "- Fully open-source licenses (MIT, Apache-2.0, BSD)\n",
        "- Deduplicated and quality-checked samples\n",
        "- Extracted using automated GitHub API pipeline\n",
        "\n",
        "## Files\n",
        "- `clean_dataset.json` â€” The dataset containing all collected samples\n",
        "- `dataset_description.md` â€” This file (short description)\n",
        "\n",
        "## Purpose\n",
        "Designed for training and evaluating AI models that generate or improve\n",
        "code comments from real-world open-source projects.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"dataset_description.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(description.strip())\n"
      ],
      "metadata": {
        "id": "Tb-it-8XiNUz"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}